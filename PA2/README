README file for Programming Assignment 2 (C++ edition)
=====================================================

Your directory should contain the following files:

 Makefile
 README
 cool.flex
 test.cl
 lextest.cc      -> [cool root]/src/PA2/lextest.cc
 mycoolc         -> [cool root]/PA2/mycoolc
 stringtab.cc    -> [cool root]/PA2/stringtab.cc
 utilities.cc    -> [cool root]/PA2/utilities.cc
 handle_flags.cc -> [cool root]/PA2/handle_flags.cc
 *.d             dependency files
 *.*             other generated files

The include (.h) files for this assignment can be found in 
[cool root]/PA2

	The Makefile contains targets for compiling and running your
	program. DO NOT MODIFY.

	The README contains this info. Part of the assignment is to fill
	the README with the write-up for your project. You should
	explain design decisions, explain why your code is correct, and
	why your test cases are adequate. It is part of the assignment
	to clearly and concisely explain things in text as well as to
	comment your code. Just edit this file.

	cool.flex is a skeleton file for the specification of the
	lexical analyzer. You should complete it with your regular
	expressions, patterns and actions. 

	test.cl is a COOL program that you can test the lexical
	analyzer on. It contains some errors, so it won't compile with
	coolc. However, test.cl does not exercise all lexical
	constructs of COOL and part of your assignment is to rewrite
	test.cl with a complete set of tests for your lexical analyzer.

	cool-parse.h contains definitions that are used by almost all parts
	of the compiler. DO NOT MODIFY.

	stringtab.{cc|h} and stringtab_functions.h contains functions
        to manipulate the string tables.  DO NOT MODIFY.

	utilities.{cc|h} contains functions used by the main() part of
	the lextest program. You may want to use the strdup() function
	defined in here. Remember that you should not print anything
	from inside cool.flex! DO NOT MODIFY.

	lextest.cc contains the main function which will call your
	lexer and print out the tokens that it returns.  DO NOT MODIFY.

	mycoolc is a shell script that glues together the phases of the
	compiler using Unix pipes instead of statically linking code.  
	While inefficient, this architecture makes it easy to mix and match
	the components you write with those of the course compiler.
	DO NOT MODIFY.	

        cool-lexer.cc is the scanner generated by flex from cool.flex.
        DO NOT MODIFY IT, as your changes will be overritten the next
        time you run flex.

 	The *.d files are automatically generated Makefiles that capture
 	dependencies between source and header files in this directory.
 	These files are updated automatically by Makefile; see the gmake
 	documentation for a detailed explanation.

Instructions
------------

	To compile your lextest program type:

	% make lexer

	Run your lexer by putting your test input in a file 'foo.cl' and
	run the lextest program:

	% ./lexer foo.cl

	To run your lexer on the file test.cl type:

	% make dotest

	If you think your lexical analyzer is correct and behaves like
	the one we wrote, you can actually try 'mycoolc' and see whether
	it runs and produces correct code for any examples.
	If your lexical analyzer behaves in an
	unexpected manner, you may get errors anywhere, i.e. during
	parsing, during semantic analysis, during code generation or
	only when you run the produced code on spim. So beware.

	If you change architectures you must issue

	% make clean

	when you switch from one type of machine to the other.
	If at some point you get weird errors from the linker,	
	you probably forgot this step.

	GOOD LUCK!

---8<------8<------8<------8<---cut here---8<------8<------8<------8<---




Write-up for PA2
----------------

by  E/17/068 Dinuransika
    E/17/154 Akilax0
    

Flex requires a set of rules to be defined to build the lexical analyze
For this assignment we are required to edit the cool.flex file which will
then be used by Flex to create the lexer for COOL programming language.

Usually the .flex file contains four main parts divided as

    %{
    Declarations    -> Definitions for the C code.
    %}
    Definitions	    -> Gives definitions to the regex.
    %%
    Rules	    -> Rules/ Regex to analyze tokens.
    %%
    User Subroutines   -> C code appended to the lexical analyzer


====LEXICAL STRUCTURE====


The main categories the lexical analyzer must identify is as follows

- Integers
- Type identifiers
- Object idnetifiers
- Special notation
- Strings
- Keywords
- Whitespaces
- Comments


Integers
---------

Defined as non-empty strings from 0-9.
    [0-9]+

On integer rule:
   On regex match create an entry on the inttable and assign as symbol. The
   integer is passed as a string to create the Entry. Return token value
   defined by INT_CONST.

Type Identifiers
-----------------

Defined as string with at least one character starting with an Uppercase.
    [A-Z]([a-zA-Z0-9_])*

On type identifier rule:
   On regex match create an entry on the idtable and assign as symbol. The
   TypeID is passed as string to create the Entry. Return token value defined
   by TYPEID.

Object Identifiers
-------------------

Defined as string with at least one character starting with an lowercase.
    [a-z]([a-zA-Z0-9_])*

On Object Identifier rule:
   On regex match create an entry on the idtable and assign as symbol. The
   ObjectID is passed as string to create the Entry, Return token value
   defined by OBJECTID. 

Keywords
---------

The set of keywords found in COOL are as follows,
- class
- else
- fi
- if
- in
- inherits
- isvoid
- let
- loop
- pool
- then
- case
- esac
- new
- of
- not

Defined as exact keywords case insensitive 
    (?i:<keyword>)


On keyword rule:
    On regex match return token value defined in cool-parser.h


Note: all token values are defined in the cool-parser.h assigning unique id
to each of them.


All keywords are handled as above except the boolean statements TRUE and
FALSE.

Defined as first letter simple and rest case insensitive
    true    -> t(?i:rue)
    false   -> f(?i:alse)

On boolean rule 
    Return token as BOOL_CONST and assign cool_yylval.boolean as true or
    false.



Comments
---------

Single line comments that take the form of 
    -- comment

Anything after a '--' is taken as a comment. 


In the case of multiline comments 

We use start states

Exclusive start state as COMMENT is defined to keep track of Opening and closing of comments.

On (* the comment gets started by using BEGIN(COMMENT) on comment end we
	BEGIN(INTIAL) state. All while the lexer is running the default start
	state is taken as INITIAL. In this instance by intializing it we are
	closing the COMMENT state. Furthermore a variable as comment_depth
	is defined to keep track of the nested comments.

On (*	    -> begin comment state and increment comment_depth.

	While the Start state COMMENT is active if we encounter ,
    (*	    -> increment comment depth.

    EOF	    -> Begin INTIAL state and set error_msg of cool_yylval as 
		"EOF in comment". Then return ERROR token.

    \n	    -> Increment the parsing line by curr_lineno++;

   *)	    -> On end of comment check if the comment depth is 0. if so clear
the COMMENT state.
    .	    -> all other characters are ignored as comments.

When *) matched without opening comment make cool_yylval.error_msg as
"Unmatched *)" and returns ERROR token.


Strings
--------

String in cool are defined within " ". Hence on " we start an exclusive state for STRING. 

The regex match is done by using the QUOTE = \" regex definition.
To keep track of string by iterating through each charcter we use the defined
string_buf[MAX_STR_CONST]
and string_buf_ptr


Once STRING state is active,

     \"	    -> append '\0' to string and begin INITIAL. Create Entry on
     string table using string_buf and assign to symbol of cool_yylval. Returns the STR_CONST
     token value.

    \0	    -> returns ERROR with message "String contains null character"
    
    <<EOF>> -> return ERROR with message "EOF in string"

    \n|\b|\t -> Check for exceeding string length if not append to string.

    \c	    -> Check for exceeding string length if not append 'c' to string.

    .	    -> All other characters gets appended to the string buffer while
    checking for max length.

Special notations
------------------

All special notations are passed as it is to the output file except the
concatanated notations of 
    LE
    ASSIGN
    DARROW

which return tokens from the cool-parser.h

====Some exra stuff we picked up=======

yytext -> Matched text
yyleng -> Matched text length
yylex()
ECHO -> output yytext
REJECT -> run the next best rule
BEGIN -> followed by start condition name to place scanner
yymore() -> if scanner matches another rule appends ytext to next token
yyless(n) -> skips first n characters of yytext
unput(c) -> put c in input file and remove yytext
input() -> reads next character from input



TESTING
===============

Main tests done using provided example codes 

arith.cl -> corrected implementation of if and while keywords
atoi.cl  -> Same error as coolc "Class Main is not defined"
lam.cl -> error when escaped characters in strings 
    i.e -> \" \? 

rest of the files had no errors.


